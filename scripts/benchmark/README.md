# Benchmark Guide

Performance benchmarking tools for elastic-transport-js middleware refactor.

## Quick Start

```bash
npm run benchmark:all
npm run benchmark:real
npm run benchmark:gc
npm run benchmark:save-baseline [name]
npm run benchmark:flamegraph
```

## Running Benchmarks

### All Benchmarks

Run all benchmarks and generate results:

```bash
npm run benchmark:all
```

**Generates:**
- Console output with performance comparison
- `benchmark-results/gc-tracking-results.json`

### Individual Benchmarks

**Performance Benchmark:**
```bash
npm run benchmark:real
```

Outputs console comparison of Legacy vs Middleware performance across different feature combinations.

**GC Tracking Benchmark:**
```bash
npm run benchmark:gc
```

Generates `benchmark-results/gc-tracking-results.json` with:
- Garbage collection statistics (frequency, duration, types)
- Memory usage (heap, external, array buffers)
- Performance metrics (ops/sec, latency)
- System metadata (Node version, platform, CPUs)

### Save Baseline

Save current benchmark results for future comparison:

```bash
npm run benchmark:save-baseline
npm run benchmark:save-baseline my-baseline-name
```

Saves to `scripts/benchmark/baselines/[name]/`

### Flamegraph Profiling

Generate CPU flamegraph for performance analysis:

```bash
npm run benchmark:flamegraph
open profile-results/flame/flamegraph.html
```

## Output Files

| File | Generated By | Contains |
|------|--------------|----------|
| `benchmark-results/gc-tracking-results.json` | `npm run benchmark:gc` | GC stats, memory usage, performance metrics |
| `profile-results/flame/flamegraph.html` | `npm run benchmark:flamegraph` | Interactive CPU flamegraph |
| `scripts/benchmark/baselines/[name]/*` | `npm run benchmark:save-baseline` | Saved benchmark results |

## Benchmark Scripts

### benchmark-transport-real.js

Main performance benchmark comparing Legacy vs Middleware mode.

**Tests 8 scenarios:**
- Legacy: baseline, +compression, +retries, +all features
- Middleware: baseline, +compression, +retries, +all features

**Features tested:**
- Real Transport implementation
- Middleware stack (7 middleware classes)
- JSON serialization
- Gzip compression
- Connection pool
- Retry logic
- Mock network I/O (no HTTP overhead)

### benchmark-gc-tracking.js

Garbage collection and memory tracking benchmark.

**Tracks:**
- GC events (type, duration, frequency)
- Memory usage (heap, external memory)
- Performance metrics per scenario
- System metadata

**Outputs:** Structured JSON to `benchmark-results/gc-tracking-results.json`

### run-all-benchmarks.ts

Runner script that executes all benchmarks sequentially.

### save-baseline.ts

Utility to save current benchmark results as baseline for comparison.

### profile-benchmark.ts

Profiling wrapper for running benchmarks with various profilers (0x, clinic.js, node --prof).

## Interpreting Results

### Performance Comparison

```
Side-by-Side Comparison (Legacy vs Middleware)
Feature Set               Legacy (ms)     Middleware (ms)    Overhead
----------------------------------------------------------------------
Baseline                  0.003           0.002              -33.3%
With compression          0.029           0.022              -24.1%
With retries              0.002           0.002              +0.0%
All features              0.024           0.021              -12.5%
```

**Overhead interpretation:**
- Negative percentage: Middleware is faster
- Positive percentage: Middleware is slower
- Target: < 20% overhead acceptable

### GC Tracking JSON Structure

```json
{
  "metadata": {
    "timestamp": "2025-11-07T16:33:13.994Z",
    "nodeVersion": "v24.9.0",
    "platform": "darwin",
    "arch": "arm64",
    "cpus": 14
  },
  "results": [
    {
      "scenario": "Legacy (baseline)",
      "performance": {
        "iterations": 5000,
        "avgLatencyMs": "0.003",
        "opsPerSec": 344967
      },
      "gc": {
        "totalEvents": 5,
        "totalDuration": 12.5,
        "avgDuration": 2.5,
        "byType": {
          "scavenge": { "count": 4, "avgDuration": 2.0 },
          "mark-sweep-compact": { "count": 1, "avgDuration": 6.5 }
        }
      },
      "memory": {
        "delta": {
          "heapUsed": 1234567,
          "heapTotal": 2345678
        }
      }
    }
  ]
}
```

## Performance Targets

| Metric | Target | Rationale |
|--------|--------|-----------|
| Middleware overhead | < 20% | Acceptable for 7-class middleware stack |
| GC pause time | < 10ms | Avoid blocking event loop |
| Memory increase | < 50MB | Keep memory footprint reasonable |
| Compression overhead | Equal in both modes | Proves independence from middleware |

## Advanced Profiling

### Clinic.js

```bash
npm install -g clinic

clinic doctor -- node scripts/benchmark/benchmark-transport-real.js
clinic flame -- node scripts/benchmark/benchmark-transport-real.js
clinic bubbleprof -- node scripts/benchmark/benchmark-transport-real.js
```

### V8 CPU Profiling

```bash
node --prof scripts/benchmark/benchmark-transport-real.js
node --prof-process isolate-*.log > profile-results/v8-profile.txt
cat profile-results/v8-profile.txt
```

### Chrome DevTools

```bash
node --inspect-brk scripts/benchmark/benchmark-transport-real.js
```

Open `chrome://inspect` in Chrome, click "inspect", then use Profiler tab.

## Tips for Accurate Benchmarks

1. **Minimize system load:** Close unnecessary applications
2. **Multiple runs:** Run benchmarks 3-5 times and average results
3. **Consistent environment:** Use same Node.js version across runs
4. **Warm-up:** Benchmarks include 100 warm-up iterations for JIT optimization

## Troubleshooting

**Inconsistent results (> 20% variance):**
- Increase iterations in benchmark scripts
- Close background applications
- Run on AC power (prevents thermal throttling)

**High compression overhead:**
- Normal behavior (gzip/gunzip is CPU intensive)
- Should be equal in Legacy and Middleware modes

**Unexpected flamegraph hotspots:**
- Ensure build is current: `npm run build`
- Check if test data is realistic
- Profile with `--inspect` for detailed analysis
